import re
import requests
from datetime import datetime
from typing import List, Dict, Any, Optional
from dateutil import parser as date_parser
from bs4 import BeautifulSoup

from workflow_state import WorkflowState, ArticleInfo, FilterConditions
from api_request import get_account_info, get_articles


def extract_account_keyword_node(state: WorkflowState) -> WorkflowState:
    """ä»ç”¨æˆ·è¾“å…¥ä¸­æå–å…¬ä¼—å·å…³é”®è¯"""
    user_input = state["user_input"]
    print(f"[DEBUG] è¾“å…¥: {user_input}")
    
    # ç®€å•æå–é€»è¾‘ï¼Œå¯ä»¥æ ¹æ®éœ€è¦æ”¹è¿›
    # å‡è®¾ç”¨æˆ·è¾“å…¥æ ¼å¼ç±»ä¼¼ï¼š"è¯·æŸ¥è¯¢é“¶è¡Œç§‘æŠ€ç ”ç©¶ç¤¾çš„æ–‡ç« "
    keyword_patterns = [
        r"æŸ¥è¯¢(.+?)çš„æ–‡ç« ",
        r"æœç´¢(.+?)å…¬ä¼—å·",
        r"å…¬ä¼—å·ï¼š(.+)",
        r"å…³é”®è¯ï¼š(.+)",
    ]
    
    account_keyword = ""
    for pattern in keyword_patterns:
        match = re.search(pattern, user_input)
        if match:
            account_keyword = match.group(1).strip()
            print(f"[DEBUG] é€šè¿‡æ¨¡å¼ '{pattern}' æå–åˆ°å…³é”®è¯: {account_keyword}")
            break
    
    if not account_keyword:
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ç‰¹å®šæ¨¡å¼ï¼Œå°è¯•æå–ç¬¬ä¸€ä¸ªä¸­æ–‡è¯ç»„
        chinese_words = re.findall(r'[\u4e00-\u9fff]+', user_input)
        if chinese_words:
            account_keyword = chinese_words[0]
            print(f"[DEBUG] é€šè¿‡ä¸­æ–‡è¯ç»„æå–åˆ°å…³é”®è¯: {account_keyword}")
    
    state["account_keyword"] = account_keyword
    print(f"[DEBUG] æœ€ç»ˆå…³é”®è¯: {account_keyword}")
    return state


def get_account_info_node(state: WorkflowState) -> WorkflowState:
    """è·å–å…¬ä¼—å·ä¿¡æ¯"""
    keyword = state["account_keyword"]
    print(f"[DEBUG] æœç´¢å…³é”®è¯: {keyword}")
    if not keyword:
        state["error_message"] = "æœªèƒ½æå–åˆ°å…¬ä¼—å·å…³é”®è¯"
        return state
    
    try:
        account_info = get_account_info(keyword)
        print(f"[DEBUG] APIè¿”å›ç»“æœ: {account_info}")
        
        # æ ¹æ®å®é™…APIè¿”å›ç»“æ„è§£æ
        if (account_info and 
            account_info.get("base_resp", {}).get("ret") == 0 and  # æ£€æŸ¥è¿”å›çŠ¶æ€
            account_info.get("list") and 
            len(account_info["list"]) > 0):
            
            # å–ç¬¬ä¸€ä¸ªåŒ¹é…çš„å…¬ä¼—å·
            first_account = account_info["list"][0]
            state["account_info"] = first_account
            state["fake_id"] = first_account.get("fakeid")  # æ³¨æ„æ˜¯ fakeid ä¸æ˜¯ fake_id
            
            nickname = first_account.get("nickname", "Unknown")
            fakeid = first_account.get("fakeid", "")
            signature = first_account.get("signature", "")
            
            print(f"[DEBUG] æ‰¾åˆ°å…¬ä¼—å·: {nickname}")
            print(f"[DEBUG] fakeid: {fakeid}")
            print(f"[DEBUG] ç®€ä»‹: {signature}")
            
        else:
            error_msg = "æœªæ‰¾åˆ°åŒ¹é…çš„å…¬ä¼—å·"
            if account_info:
                # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯
                base_resp = account_info.get("base_resp", {})
                if base_resp.get("ret") != 0:
                    error_msg = f"APIé”™è¯¯: {base_resp.get('err_msg', 'æœªçŸ¥é”™è¯¯')}"
                elif account_info.get("total", 0) == 0:
                    error_msg = f"æœªæ‰¾åˆ°å…³é”®è¯ä¸º '{keyword}' çš„å…¬ä¼—å·"
            
            state["error_message"] = error_msg
            
    except Exception as e:
        state["error_message"] = f"è·å–å…¬ä¼—å·ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}"
    
    return state


def fetch_articles_with_smart_filtering_node(state: WorkflowState) -> WorkflowState:
    """æ™ºèƒ½è·å–æ–‡ç« ï¼šæ ¹æ®ç­›é€‰æ¡ä»¶åŠ¨æ€è·å–è¶³å¤Ÿæ•°é‡çš„æ–‡ç« ï¼Œæ”¯æŒæ—¶é—´èŒƒå›´ä¼˜åŒ–"""
    fake_id = state["fake_id"]
    conditions = state.get("filter_conditions", {})
    print(f"[DEBUG] å¼€å§‹æ™ºèƒ½è·å–æ–‡ç« ï¼Œfake_id: {fake_id}")
    print(f"[DEBUG] ç­›é€‰æ¡ä»¶: {conditions}")
    
    if not fake_id:
        state["error_message"] = "ç¼ºå°‘å…¬ä¼—å·fake_id"
        return state
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´èŒƒå›´æ¡ä»¶ï¼Œå¯ç”¨ä¼˜åŒ–ç­–ç•¥
    start_date = conditions.get("start_date")
    end_date = conditions.get("end_date")
    has_time_range = start_date or end_date
    
    if has_time_range:
        print(f"[TIME-OPT] æ£€æµ‹åˆ°æ—¶é—´èŒƒå›´æ¡ä»¶ï¼Œå¯ç”¨æ—¶é—´ä¼˜åŒ–ç­–ç•¥")
        print(f"[TIME-OPT] æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")
    
    all_articles = []
    filtered_articles = []
    begin = 0
    size = 20
    max_pages = 50
    target_count = conditions.get("max_articles", 20)
    
    # æ—¶é—´ä¼˜åŒ–ç›¸å…³å˜é‡
    found_in_range = False  # æ˜¯å¦æ‰¾åˆ°è¿‡åœ¨æ—¶é—´èŒƒå›´å†…çš„æ–‡ç« 
    api_calls = 0
    
    try:
        for page in range(max_pages):
            api_calls += 1
            # è·å–å½“å‰é¡µæ–‡ç« 
            articles_response = get_articles(fake_id, begin, size)
            print(f"[DEBUG] ç¬¬{page + 1}é¡µAPIè¿”å›")
            
            # æ£€æŸ¥APIè¿”å›çŠ¶æ€å’Œæ•°æ®
            if not articles_response:
                print(f"[DEBUG] ç¬¬{page + 1}é¡µAPIè¿”å›ä¸ºç©ºï¼Œåœæ­¢è·å–")
                break
                
            # æ£€æŸ¥APIçŠ¶æ€
            base_resp = articles_response.get("base_resp", {})
            if base_resp.get("ret") != 0:
                error_msg = f"APIé”™è¯¯: {base_resp.get('err_msg', 'æœªçŸ¥é”™è¯¯')}"
                print(f"[DEBUG] {error_msg}")
                state["error_message"] = error_msg
                return state
            
            # è·å–æ–‡ç« åˆ—è¡¨
            articles_data = articles_response.get("articles", [])
            if not articles_data or len(articles_data) == 0:
                print(f"[DEBUG] ç¬¬{page + 1}é¡µæ–‡ç« åˆ—è¡¨ä¸ºç©ºï¼Œåœæ­¢è·å–")
                break
            
            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼å¹¶æ·»åŠ åˆ°æ€»åˆ—è¡¨
            current_page_articles = []
            page_in_range_count = 0
            early_termination = False
            
            for article in articles_data:
                article_info = ArticleInfo(
                    title=article.get("title", ""),
                    publish_time=str(article.get("update_time", article.get("create_time", ""))),
                    link=article.get("link", ""),
                    content_url=article.get("link", ""),
                    fake_id=fake_id
                )
                all_articles.append(article_info)
                current_page_articles.append(article_info)
                
                # å¦‚æœæœ‰æ—¶é—´èŒƒå›´æ¡ä»¶ï¼Œè¿›è¡Œæ—¶é—´ä¼˜åŒ–åˆ¤æ–­
                if has_time_range:
                    article_time = parse_article_time(article_info["publish_time"])
                    if article_time:
                        # æ£€æŸ¥æ˜¯å¦åœ¨æ—¶é—´èŒƒå›´å†…
                        in_range = True
                        if start_date and article_time < start_date:
                            # æ–‡ç« æ—¶é—´æ—©äºå¼€å§‹æ—¶é—´
                            if found_in_range:
                                # å¦‚æœä¹‹å‰å·²ç»æ‰¾åˆ°è¿‡åœ¨èŒƒå›´å†…çš„æ–‡ç« ï¼Œç°åœ¨å¯ä»¥æå‰ç»ˆæ­¢
                                print(f"[TIME-OPT] ğŸš€ æå‰ç»ˆæ­¢ï¼šæ–‡ç« æ—¶é—´ {article_time.strftime('%Y-%m-%d')} æ—©äºå¼€å§‹æ—¶é—´ {start_date.strftime('%Y-%m-%d')}")
                                early_termination = True
                                break
                            in_range = False
                        elif end_date and article_time > end_date:
                            # æ–‡ç« æ—¶é—´æ™šäºç»“æŸæ—¶é—´ï¼Œè·³è¿‡ä½†ç»§ç»­è·å–
                            print(f"[TIME-OPT] è·³è¿‡æ–‡ç« ï¼š{article_info['title'][:30]}... (æ—¶é—´æ™šäºç»“æŸæ—¶é—´)")
                            in_range = False
                        
                        if in_range:
                            found_in_range = True
                            page_in_range_count += 1
            
            # å¦‚æœéœ€è¦æå‰ç»ˆæ­¢ï¼Œè·³å‡ºå¾ªç¯
            if early_termination:
                print(f"[TIME-OPT] æå‰ç»ˆæ­¢è·å–ï¼ŒèŠ‚çœäº† {max_pages - page - 1} é¡µçš„APIè°ƒç”¨")
                break
            
            # å¯¹å½“å‰ç´¯ç§¯çš„æ‰€æœ‰æ–‡ç« è¿›è¡Œç­›é€‰
            filtered_articles = apply_filters(all_articles, conditions)
            
            if has_time_range:
                print(f"[DEBUG] ç¬¬{page + 1}é¡µè·å– {len(current_page_articles)} ç¯‡ï¼Œæ—¶é—´èŒƒå›´å†… {page_in_range_count} ç¯‡ï¼Œç´¯è®¡ç­›é€‰å {len(filtered_articles)} ç¯‡")
            else:
                print(f"[DEBUG] ç¬¬{page + 1}é¡µè·å– {len(current_page_articles)} ç¯‡æ–‡ç« ï¼Œç´¯è®¡ {len(all_articles)} ç¯‡ï¼Œç­›é€‰å {len(filtered_articles)} ç¯‡")
            
            # æ£€æŸ¥æ˜¯å¦æ»¡è¶³æ¡ä»¶
            if is_filtering_complete(filtered_articles, conditions):
                print(f"[DEBUG] å·²æ»¡è¶³ç­›é€‰æ¡ä»¶ï¼Œåœæ­¢è·å–")
                break
            
            # å¦‚æœè¿”å›çš„æ–‡ç« æ•°é‡å°‘äºsizeï¼Œè¯´æ˜å·²ç»æ˜¯æœ€åä¸€é¡µ
            if len(articles_data) < size:
                print(f"[DEBUG] å·²åˆ°æœ€åä¸€é¡µï¼Œåœæ­¢è·å–")
                break
            
            begin += size
    
    except Exception as e:
        state["error_message"] = f"è·å–æ–‡ç« åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}"
        return state
    
    # æœ€ç»ˆç­›é€‰ï¼ˆç¡®ä¿æ•°é‡é™åˆ¶ï¼‰
    if conditions.get("max_articles") and len(filtered_articles) > conditions["max_articles"]:
        filtered_articles = filtered_articles[:conditions["max_articles"]]
    
    state["all_articles"] = all_articles
    state["filtered_articles"] = filtered_articles
    
    if has_time_range:
        print(f"[TIME-OPT] æ—¶é—´ä¼˜åŒ–æ•ˆæœï¼šAPIè°ƒç”¨ {api_calls} æ¬¡ï¼Œæœ€ç»ˆç»“æœï¼šæ€»æ–‡ç«  {len(all_articles)} ç¯‡ï¼Œç­›é€‰å {len(filtered_articles)} ç¯‡")
    else:
        print(f"[DEBUG] æœ€ç»ˆç»“æœï¼šæ€»æ–‡ç«  {len(all_articles)} ç¯‡ï¼Œç­›é€‰å {len(filtered_articles)} ç¯‡")
    
    return state


def parse_article_time(time_str: str) -> Optional[datetime]:
    """è§£ææ–‡ç« æ—¶é—´æˆ³"""
    if not time_str or not time_str.strip():
        return None
    
    try:
        if time_str.isdigit():
            return datetime.fromtimestamp(int(time_str))
        else:
            # å°è¯•å…¶ä»–æ—¥æœŸæ ¼å¼
            from dateutil import parser as date_parser
            return date_parser.parse(time_str)
    except:
        return None


def apply_filters(articles: List[ArticleInfo], conditions: FilterConditions) -> List[ArticleInfo]:
    """åº”ç”¨ç­›é€‰æ¡ä»¶åˆ°æ–‡ç« åˆ—è¡¨"""
    filtered = articles.copy()
    
    # æŒ‰æ ‡é¢˜å…³é”®è¯ç­›é€‰
    if conditions.get("title_keywords"):
        keywords = conditions["title_keywords"]
        filtered = [
            article for article in filtered
            if any(keyword in article["title"] for keyword in keywords)
        ]
        print(f"[DEBUG] æŒ‰å…³é”®è¯ {keywords} ç­›é€‰åå‰©ä½™ {len(filtered)} ç¯‡æ–‡ç« ")
    
    # æŒ‰æ—¶é—´ç­›é€‰
    if conditions.get("start_date") or conditions.get("end_date"):
        date_filtered = []
        for article in filtered:
            try:
                publish_time = article["publish_time"]
                if isinstance(publish_time, str):
                    # å°è¯•è§£ææ—¶é—´æˆ³æˆ–æ—¥æœŸå­—ç¬¦ä¸²
                    if publish_time.isdigit():
                        article_date = datetime.fromtimestamp(int(publish_time))
                    else:
                        article_date = date_parser.parse(publish_time)
                else:
                    continue
                
                if conditions.get("start_date") and article_date < conditions["start_date"]:
                    continue
                if conditions.get("end_date") and article_date > conditions["end_date"]:
                    continue
                
                date_filtered.append(article)
            except:
                # å¦‚æœæ—¥æœŸè§£æå¤±è´¥ï¼Œä¿ç•™æ–‡ç« 
                date_filtered.append(article)
        
        filtered = date_filtered
        print(f"[DEBUG] æŒ‰æ—¶é—´ç­›é€‰åå‰©ä½™ {len(filtered)} ç¯‡æ–‡ç« ")
    
    return filtered


def is_filtering_complete(filtered_articles: List[ArticleInfo], conditions: FilterConditions) -> bool:
    """æ£€æŸ¥ç­›é€‰æ˜¯å¦å·²å®Œæˆï¼ˆæ»¡è¶³ç”¨æˆ·éœ€æ±‚ï¼‰"""
    target_count = conditions.get("max_articles")
    
    # å¦‚æœç”¨æˆ·æŒ‡å®šäº†æ•°é‡è¦æ±‚ï¼Œæ£€æŸ¥æ˜¯å¦å·²è¾¾åˆ°
    if target_count:
        if len(filtered_articles) >= target_count:
            return True
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ•°é‡ä½†æœ‰å…¶ä»–æ¡ä»¶ï¼Œç»§ç»­è·å–æ›´å¤šæ–‡ç« ä»¥ç¡®ä¿å……åˆ†ç­›é€‰
    # è¿™é‡Œå¯ä»¥è®¾ç½®ä¸€ä¸ªé»˜è®¤çš„"è¶³å¤Ÿ"æ•°é‡ï¼Œæ¯”å¦‚50ç¯‡
    if not target_count and len(filtered_articles) >= 50:
        return True
    
    return False


def parse_filter_conditions_node(state: WorkflowState) -> WorkflowState:
    """è§£æç”¨æˆ·è¾“å…¥çš„ç­›é€‰æ¡ä»¶"""
    user_input = state["user_input"]
    
    conditions = FilterConditions(
        title_keywords=None,
        max_articles=None,
        start_date=None,
        end_date=None
    )
    
    # æå–æ ‡é¢˜å…³é”®è¯
    keyword_patterns = [
        r"æ ‡é¢˜åŒ…å«[ï¼š:]?(.+)",
        r"å…³é”®è¯[ï¼š:]?(.+)",
        r"åŒ…å«[ï¼š:]?(.+?)çš„æ–‡ç« ",
    ]
    
    for pattern in keyword_patterns:
        match = re.search(pattern, user_input)
        if match:
            keywords = [kw.strip() for kw in match.group(1).split(",") if kw.strip()]
            conditions["title_keywords"] = keywords
            break
    
    # æå–æ–‡ç« æ•°é‡é™åˆ¶
    count_match = re.search(r"(\d+)ç¯‡|æœ€å¤š(\d+)|å‰(\d+)", user_input)
    if count_match:
        count = int(count_match.group(1) or count_match.group(2) or count_match.group(3))
        conditions["max_articles"] = count
    
    # æå–æ—¶é—´èŒƒå›´
    date_patterns = [
        r"(\d{4}-\d{1,2}-\d{1,2})",
        r"(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)",
        r"æœ€è¿‘(\d+)å¤©",
    ]
    
    for pattern in date_patterns:
        matches = re.findall(pattern, user_input)
        for match in matches:
            try:
                if "å¹´" in match and "æœˆ" in match and "æ—¥" in match:
                    # å¤„ç†ä¸­æ–‡æ—¥æœŸæ ¼å¼
                    date_str = match.replace("å¹´", "-").replace("æœˆ", "-").replace("æ—¥", "")
                    parsed_date = datetime.strptime(date_str, "%Y-%m-%d")
                else:
                    parsed_date = date_parser.parse(match)
                
                if not conditions["start_date"]:
                    conditions["start_date"] = parsed_date
                else:
                    conditions["end_date"] = parsed_date
            except:
                continue
    
    state["filter_conditions"] = conditions
    return state


def filter_articles_node(state: WorkflowState) -> WorkflowState:
    """æ ¹æ®æ¡ä»¶ç­›é€‰æ–‡ç« """
    all_articles = state["all_articles"]
    conditions = state["filter_conditions"]
    
    print(f"[DEBUG] å¼€å§‹ç­›é€‰ï¼ŒåŸå§‹æ–‡ç« æ•°: {len(all_articles)}")
    print(f"[DEBUG] ç­›é€‰æ¡ä»¶: {conditions}")
    
    filtered_articles = all_articles.copy()
    
    # æŒ‰æ ‡é¢˜å…³é”®è¯ç­›é€‰
    if conditions["title_keywords"]:
        keywords = conditions["title_keywords"]
        filtered_articles = [
            article for article in filtered_articles
            if any(keyword in article["title"] for keyword in keywords)
        ]
        print(f"[DEBUG] æŒ‰å…³é”®è¯ç­›é€‰åå‰©ä½™ {len(filtered_articles)} ç¯‡æ–‡ç« ")
    
    # æŒ‰æ—¶é—´ç­›é€‰
    if conditions["start_date"] or conditions["end_date"]:
        date_filtered = []
        for article in filtered_articles:
            try:
                publish_time = article["publish_time"]
                if isinstance(publish_time, str):
                    # å°è¯•è§£ææ—¶é—´æˆ³æˆ–æ—¥æœŸå­—ç¬¦ä¸²
                    if publish_time.isdigit():
                        article_date = datetime.fromtimestamp(int(publish_time))
                    else:
                        article_date = date_parser.parse(publish_time)
                else:
                    continue
                
                if conditions["start_date"] and article_date < conditions["start_date"]:
                    continue
                if conditions["end_date"] and article_date > conditions["end_date"]:
                    continue
                
                date_filtered.append(article)
            except:
                # å¦‚æœæ—¥æœŸè§£æå¤±è´¥ï¼Œä¿ç•™æ–‡ç« 
                date_filtered.append(article)
        
        filtered_articles = date_filtered
        print(f"[DEBUG] æŒ‰æ—¶é—´ç­›é€‰åå‰©ä½™ {len(filtered_articles)} ç¯‡æ–‡ç« ")
    
    # æŒ‰æ•°é‡é™åˆ¶
    if conditions["max_articles"] and len(filtered_articles) > conditions["max_articles"]:
        filtered_articles = filtered_articles[:conditions["max_articles"]]
        print(f"[DEBUG] æŒ‰æ•°é‡é™åˆ¶åå‰©ä½™ {len(filtered_articles)} ç¯‡æ–‡ç« ")
    
    state["filtered_articles"] = filtered_articles
    print(f"[DEBUG] æœ€ç»ˆç­›é€‰ç»“æœ: {len(filtered_articles)} ç¯‡æ–‡ç« ")
    return state